{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SbC6bkLyj-Bx"
   },
   "source": [
    "# Week 1: Lab set up and test run\n",
    "\n",
    "This week's lab is to help you set up the lab environment using either Colab or on your own computer, and ensure that you can run through code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tXe5MUBEj-Bz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vsGrpR9Hj-B0"
   },
   "source": [
    "## Loading MNIST\n",
    "\n",
    "In this lab, we will be using the MNIST dataset, which is a set of 70,000 small images of digits handwritten by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. This set has been studied so much that it is often called the “Hello World” of Machine Learning: whenever people come up with a new classification algorithm, they are curious to see how it will perform on MNIST. Whenever someone learns Machine Learning, sooner or later they tackle MNIST.\n",
    "\n",
    "Scikit-Learn provides many helper functions to download popular datasets. MNIST is one of them. The following code fetches the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3e0gmy5bj-B0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KAQJNVUYj-B1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\liamd\\Documents\\AI LABS\\WEEK 1\\Week_1_Lab_setup_and_test_run (1).ipynb Cell 5\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liamd/Documents/AI%20LABS/WEEK%201/Week_1_Lab_setup_and_test_run%20%281%29.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(X_digits)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liamd/Documents/AI%20LABS/WEEK%201/Week_1_Lab_setup_and_test_run%20%281%29.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m y_digits \u001b[39m=\u001b[39m digits\u001b[39m.\u001b[39mtarget\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/liamd/Documents/AI%20LABS/WEEK%201/Week_1_Lab_setup_and_test_run%20%281%29.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m n_samples \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39;49m(X_digits[\u001b[39m0\u001b[39;49m][\u001b[39m0\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liamd/Documents/AI%20LABS/WEEK%201/Week_1_Lab_setup_and_test_run%20%281%29.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m X_train \u001b[39m=\u001b[39m X_digits[:\u001b[39mround\u001b[39m(\u001b[39m.9\u001b[39m \u001b[39m*\u001b[39m n_samples)] \u001b[39m#we use 90% of the training data for training, and then the last 10% for test\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liamd/Documents/AI%20LABS/WEEK%201/Week_1_Lab_setup_and_test_run%20%281%29.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m y_train \u001b[39m=\u001b[39m y_digits[:\u001b[39mround\u001b[39m(\u001b[39m.9\u001b[39m \u001b[39m*\u001b[39m n_samples)]\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "X_digits = digits.data\n",
    "print(X_digits)\n",
    "y_digits = digits.target\n",
    "\n",
    "n_samples = len(X_digits[0])\n",
    "\n",
    "\n",
    "X_train = X_digits[:round(.9 * n_samples)] #we use 90% of the training data for training, and then the last 10% for test\n",
    "y_train = y_digits[:round(.9 * n_samples)]\n",
    "X_test = X_digits[round(.9 * n_samples):]\n",
    "y_test = y_digits[round(.9 * n_samples):]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yi2zYuskj-B1"
   },
   "source": [
    "## KNN classifier\n",
    "\n",
    "\n",
    "Let’s simplify the problem for now and only try to identify one digit—for example, the number 5. This “5-detector” will be an example of a binary classifier, capable of distinguishing between just two classes, 5 and not-5. Let’s create the target vectors for this classification task. Now let’s train the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "JkYfBiu2j-B2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False ...  True False False]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=4, weights='distance')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)\n",
    "print(y_train_5)\n",
    "\n",
    "\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=4)\n",
    "knn_clf.fit(X_train, y_train_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l5z9bkCNj-B2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_digit = X_digits[1719]\n",
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CarfJHv9j-B3"
   },
   "source": [
    "## Performance Measures\n",
    "\n",
    "Evaluating a classifier is often significantly trickier than evaluating a regressor, so we will spend a large part of this chapter on this topic. There are many performance measures available, so grab another coffee and get ready to learn many new concepts and acronyms!\n",
    "\n",
    "A good way to evaluate a model is to use cross-validation. Let’s use the cross_val_score() function to evaluate your KNN model using K-fold cross-validation, with three folds. Remember that K-fold crossvalidation means splitting the training set into K-folds (in this case, three), then making predictions and evaluating them on each fold using a model trained on the remaining folds.\n",
    "\n",
    "### Measuring Accuracy Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zZkMzJTpj-B3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99628942, 0.99443414, 0.99628942])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(knn_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "01g2mcrlj-B3"
   },
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5 th row and 3 rd column of the confusion matrix.\n",
    "\n",
    "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch). Instead, you can use the cross_val_predict() function. Just like the cross_val_score() function, cross_val_predict() performs K-fold cross-validation, but instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model that never saw the data during training).\n",
    "\n",
    "\n",
    "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes (y_train_pred):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "vkYeC44-j-B4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1452,    1],\n",
       "       [   6,  158]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(knn_clf, X_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxliwRbEj-B4"
   },
   "source": [
    "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 1,452 of them were correctly classified as non-5s (they are called true negatives), while the remaining 1 was wrongly classified as 5s (false positives). The second row considers the images of 5s (the positive class): 6 were wrongly classified as non-5s (false negatives), while the remaining 158 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right):"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Week_1_ML.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "e54267ee16b81c82e04bdaafb045b79a3e8afb05f9633ce8432697a8db8350ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
